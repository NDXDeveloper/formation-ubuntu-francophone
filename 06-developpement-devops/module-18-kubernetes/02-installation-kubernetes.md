# 18-2. Installation de Kubernetes avec kubeadm

üîù Retour √† la [Table des mati√®res](#table-des-mati√®res)

## Introduction

Dans ce tutoriel, nous allons apprendre √† installer et configurer un cluster Kubernetes en utilisant `kubeadm`. L'outil `kubeadm` simplifie consid√©rablement la cr√©ation d'un cluster Kubernetes fonctionnel en automatisant de nombreuses √©tapes complexes. Ce guide est con√ßu pour les d√©butants qui souhaitent mettre en place un environnement Kubernetes sur des machines Ubuntu.

## Pr√©requis

Pour suivre ce tutoriel, vous aurez besoin de :

- Au moins deux machines Ubuntu (version 20.04 LTS ou plus r√©cente)
  - Une machine qui servira de n≈ìud ma√Ætre (master node)
  - Une ou plusieurs machines qui serviront de n≈ìuds de travail (worker nodes)
- Pour chaque machine :
  - Au moins 2 CPU/c≈ìurs
  - Au moins 2 Go de RAM
  - Au moins 20 Go d'espace disque
  - Une connexion r√©seau entre toutes les machines
  - Un utilisateur avec les privil√®ges sudo
- Connaissances de base de Linux et des lignes de commande

> **Note** : Si vous ne disposez pas de plusieurs machines physiques, vous pouvez utiliser des machines virtuelles (VMs) sur votre ordinateur ou des instances dans un cloud public comme AWS, Google Cloud ou Azure.

## Vue d'ensemble de l'installation

L'installation d'un cluster Kubernetes avec kubeadm se d√©roule en plusieurs √©tapes :

1. Pr√©paration des machines (tous les n≈ìuds)
2. Installation des pr√©requis (tous les n≈ìuds)
3. Initialisation du n≈ìud ma√Ætre
4. Configuration du r√©seau des pods
5. Ajout des n≈ìuds de travail au cluster
6. V√©rification de l'installation

Suivons ces √©tapes une par une.

## √âtape 1 : Pr√©paration des machines

Ces √©tapes doivent √™tre ex√©cut√©es sur **tous les n≈ìuds** (ma√Ætre et travailleurs).

### 1.1 Mise √† jour du syst√®me

Commencez par mettre √† jour le syst√®me d'exploitation :

```bash
# Mettre √† jour la liste des paquets
sudo apt update

# Mettre √† jour les paquets install√©s
sudo apt upgrade -y
```

### 1.2 Configuration des noms d'h√¥tes

Assurez-vous que chaque machine a un nom d'h√¥te unique :

```bash
# D√©finir le nom d'h√¥te (remplacez k8s-master ou k8s-worker1 par le nom souhait√©)
# Sur le n≈ìud ma√Ætre :
sudo hostnamectl set-hostname k8s-master

# Sur le premier n≈ìud travailleur :
sudo hostnamectl set-hostname k8s-worker1

# Sur le deuxi√®me n≈ìud travailleur (si vous en avez un) :
sudo hostnamectl set-hostname k8s-worker2
```

### 1.3 Configuration du fichier /etc/hosts

Pour que les n≈ìuds puissent communiquer entre eux par nom, ajoutez les entr√©es correspondantes dans le fichier `/etc/hosts` sur **chaque machine** :

```bash
sudo nano /etc/hosts
```

Ajoutez les lignes suivantes (remplacez les adresses IP par les adresses r√©elles de vos machines) :

```
192.168.1.10 k8s-master
192.168.1.11 k8s-worker1
192.168.1.12 k8s-worker2
```

### 1.4 D√©sactivation du swap

Kubernetes exige que le swap soit d√©sactiv√© pour des performances pr√©visibles :

```bash
# D√©sactiver le swap imm√©diatement
sudo swapoff -a

# D√©sactiver le swap de fa√ßon permanente en commentant la ligne du fichier fstab
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

### 1.5 Configuration des modules du noyau requis

Kubernetes n√©cessite certains modules du noyau Linux :

```bash
# Cr√©er le fichier de configuration pour les modules
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

# Charger les modules
sudo modprobe overlay
sudo modprobe br_netfilter
```

### 1.6 Configuration des param√®tres r√©seau

```bash
# Cr√©er le fichier de configuration pour les param√®tres r√©seau
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Appliquer les param√®tres
sudo sysctl --system
```

## √âtape 2 : Installation des pr√©requis

Ces √©tapes doivent √©galement √™tre ex√©cut√©es sur **tous les n≈ìuds**.

### 2.1 Installation du runtime de conteneurs (containerd)

Kubernetes a besoin d'un runtime de conteneurs. Nous utiliserons containerd, qui est maintenant recommand√© :

```bash
# Installer les paquets n√©cessaires
sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release

# Ajouter la cl√© GPG de Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Ajouter le d√©p√¥t Docker
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Mettre √† jour la liste des paquets
sudo apt update

# Installer containerd
sudo apt install -y containerd.io
```

### 2.2 Configuration de containerd

Il faut configurer containerd pour qu'il utilise le driver systemd :

```bash
# Cr√©er le r√©pertoire de configuration
sudo mkdir -p /etc/containerd

# G√©n√©rer la configuration par d√©faut
containerd config default | sudo tee /etc/containerd/config.toml

# Modifier la configuration pour utiliser systemd
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml

# Red√©marrer containerd
sudo systemctl restart containerd
sudo systemctl enable containerd
```

### 2.3 Installation des outils Kubernetes

Maintenant, installons les composants Kubernetes (kubeadm, kubelet et kubectl) :

```bash
# Ajouter la cl√© GPG de Kubernetes
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Ajouter le d√©p√¥t Kubernetes
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Mettre √† jour la liste des paquets
sudo apt update

# Installer les composants Kubernetes
sudo apt install -y kubelet kubeadm kubectl

# Marquer les paquets pour √©viter les mises √† jour automatiques
sudo apt-mark hold kubelet kubeadm kubectl
```

## √âtape 3 : Initialisation du n≈ìud ma√Ætre

Cette √©tape ne doit √™tre ex√©cut√©e que sur le **n≈ìud ma√Ætre**.

### 3.1 Initialisation du cluster avec kubeadm

```bash
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
```

> L'option `--pod-network-cidr=10.244.0.0/16` est sp√©cifique √† certains plugins r√©seau comme Flannel. Si vous pr√©voyez d'utiliser un autre plugin, vous devrez peut-√™tre ajuster cette valeur.

√Ä la fin de l'ex√©cution, vous verrez un message similaire √† celui-ci :

```
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.10:6443 --token abcdef.1234567890abcdef \
    --discovery-token-ca-cert-hash sha256:1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef
```

### 3.2 Configuration de kubectl pour l'utilisateur normal

Pour utiliser kubectl sans √™tre root, ex√©cutez les commandes suivantes sur le n≈ìud ma√Ætre :

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

> **Important** : Conservez la commande `kubeadm join` qui appara√Æt √† la fin de l'initialisation. Vous en aurez besoin pour ajouter les n≈ìuds de travail au cluster.

## √âtape 4 : Configuration du r√©seau des pods

Le r√©seau des pods doit √™tre configur√© pour que les conteneurs puissent communiquer entre eux. Nous utiliserons Calico, qui est l'une des solutions de r√©seau les plus populaires pour Kubernetes.

Sur le **n≈ìud ma√Ætre**, ex√©cutez :

```bash
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

> **Alternative** : Si vous pr√©f√©rez utiliser Flannel √† la place de Calico, vous pouvez ex√©cuter :
> ```bash
> kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
> ```

V√©rifiez que les pods du syst√®me sont en cours d'ex√©cution :

```bash
kubectl get pods --all-namespaces
```

Attendez que tous les pods soient dans l'√©tat "Running" avant de continuer.

## √âtape 5 : Ajout des n≈ìuds de travail au cluster

Sur chaque **n≈ìud de travail**, ex√©cutez la commande `kubeadm join` que vous avez obtenue √† la fin de l'initialisation du n≈ìud ma√Ætre. Elle ressemblera √† ceci :

```bash
sudo kubeadm join 192.168.1.10:6443 --token abcdef.1234567890abcdef \
    --discovery-token-ca-cert-hash sha256:1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef
```

> **Note** : Si vous avez perdu le token ou s'il a expir√© (les tokens expirent apr√®s 24 heures), vous pouvez en g√©n√©rer un nouveau sur le n≈ìud ma√Ætre avec :
> ```bash
> kubeadm token create --print-join-command
> ```

## √âtape 6 : V√©rification de l'installation

Sur le **n≈ìud ma√Ætre**, v√©rifiez que les n≈ìuds ont bien rejoint le cluster :

```bash
kubectl get nodes
```

Vous devriez voir tous vos n≈ìuds list√©s. Il se peut qu'ils soient dans l'√©tat "NotReady" pendant quelques minutes, le temps que le r√©seau des pods soit pleinement op√©rationnel.

Apr√®s quelques minutes, v√©rifiez √† nouveau :

```bash
kubectl get nodes
```

Tous les n≈ìuds devraient maintenant √™tre dans l'√©tat "Ready".

V√©rifiez √©galement les pods du syst√®me :

```bash
kubectl get pods --all-namespaces
```

Tous les pods devraient √™tre dans l'√©tat "Running".

## Probl√®mes courants et d√©pannage

### 1. Les n≈ìuds restent en √©tat "NotReady"

V√©rifiez les journaux :

```bash
kubectl describe node <nom-du-n≈ìud>
```

Assurez-vous que le plugin r√©seau est correctement install√© :

```bash
kubectl get pods -n kube-system
```

### 2. Probl√®mes de r√©solution DNS

Si vous rencontrez des probl√®mes de DNS dans vos pods, v√©rifiez que CoreDNS fonctionne correctement :

```bash
kubectl get pods -n kube-system -l k8s-app=kube-dns
```

### 3. Erreurs lors de l'initialisation avec kubeadm

Si vous rencontrez des erreurs lors de l'initialisation, vous pouvez r√©initialiser le n≈ìud :

```bash
sudo kubeadm reset
```

Puis r√©essayez l'initialisation avec des options suppl√©mentaires si n√©cessaire.

### 4. R√©cup√©ration apr√®s une panne de n≈ìud ma√Ætre

Si le n≈ìud ma√Ætre tombe en panne, vous devrez restaurer √† partir d'une sauvegarde ou recr√©er le cluster.

## Configuration suppl√©mentaire

### Permettre la planification des pods sur le n≈ìud ma√Ætre

Par d√©faut, les pods des applications ne sont pas planifi√©s sur le n≈ìud ma√Ætre. Si vous avez un petit cluster ou un cluster de test, vous pouvez permettre la planification des pods sur le n≈ìud ma√Ætre :

```bash
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

### Installation du tableau de bord Kubernetes (optionnel)

Pour une gestion plus visuelle, vous pouvez installer le tableau de bord Kubernetes :

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
```

Cr√©ez un utilisateur administrateur pour le tableau de bord :

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF
```

Obtenez le token pour vous connecter au tableau de bord :

```bash
kubectl -n kubernetes-dashboard create token admin-user
```

Lancez le proxy pour acc√©der au tableau de bord :

```bash
kubectl proxy
```

Acc√©dez au tableau de bord √† l'adresse suivante :
http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

Utilisez le token obtenu pr√©c√©demment pour vous connecter.

## Mise √† niveau du cluster

Pour mettre √† niveau le cluster Kubernetes, consultez la documentation officielle car cette proc√©dure varie selon les versions.

## Configuration d'un stockage persistant

Pour des applications avec √©tat, vous aurez besoin d'un stockage persistant. Voici comment configurer un simple provisioner de stockage local :

```bash
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
```

D√©finissez-le comme provisioner par d√©faut :

```bash
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

## Conclusion

F√©licitations ! Vous avez maintenant un cluster Kubernetes fonctionnel install√© avec kubeadm. Ce cluster comprend :

- Un n≈ìud ma√Ætre qui g√®re l'√©tat du cluster
- Un ou plusieurs n≈ìuds de travail qui ex√©cutent vos applications
- Un r√©seau de pods fonctionnel (Calico ou Flannel)
- kubectl configur√© pour g√©rer le cluster

Vous √™tes maintenant pr√™t √† d√©ployer vos applications sur Kubernetes. Dans les prochains modules, nous explorerons comment d√©ployer et g√©rer des applications dans votre nouveau cluster.

## Prochaines √©tapes

Voici quelques sujets √† explorer maintenant que votre cluster est op√©rationnel :

1. D√©ployer votre premi√®re application dans Kubernetes
2. Configurer la persistance des donn√©es
3. Exposer des services √† l'ext√©rieur du cluster
4. Mettre en place des strat√©gies de mise √† l'√©chelle automatique
5. Configurer la surveillance et la journalisation

## Ressources suppl√©mentaires

- [Documentation officielle de kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)
- [Documentation de Calico](https://docs.projectcalico.org/)
- [Documentation du tableau de bord Kubernetes](https://github.com/kubernetes/dashboard)
- [Kubernetes Basics Tutorial](https://kubernetes.io/docs/tutorials/kubernetes-basics/)

‚è≠Ô∏è [D√©ploiement d'un cluster local](/06-developpement-devops/module-18-kubernetes/03-deploiement-cluster.md)
